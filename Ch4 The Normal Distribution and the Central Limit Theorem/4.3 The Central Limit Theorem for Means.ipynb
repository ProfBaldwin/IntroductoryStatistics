{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 The Central Limit Theorem for Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Compute probabilities using the Central Limit Theorem and demonstrate the ability to interpret sampling distributions of both population proportions and means.\n",
    "- Analyze an application in the disciplines business, social sciences, psychology, life sciences, health science, and education, and utilize the correct statistical processes to arrive at a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Central Limit Theorem\n",
    "\n",
    "Suppose $X$ is a random variable with a distribution that may be known or unknown (it can be *any* distribution). Using a subscript that matches the random variable, suppose:\n",
    "\n",
    "- $\\mu_X$ = the mean of $X$\n",
    "- $\\sigma_X$ = the standard deviation of $X$\n",
    "\n",
    "If you draw random samples of size n, then as n increases, the random variable $\\overline{X}$  which consists of sample means, tends to be **normally distributed** and\n",
    "\n",
    "$$ \\overline{X} \\sim N\\left(\\mu_X, \\frac{\\sigma_X}{\\sqrt{n}}\\right). $$\n",
    "\n",
    "The **central limit theorem** for sample means says that if you keep drawing larger and larger samples (such as rolling one, two, five, and finally, ten dice) and **calculating their means,** the sample means form their own **normal distribution** (the sampling distribution). The normal distribution has the same mean as the original distribution and a variance that equals the original variance divided by the sample size. Standard deviation is the square root of variance, so the standard deviation of the sampling distribution is the standard deviation of the original distribution divided by the square root of $n$. The variable $n$ is the number of values that are averaged together, not the number of times the experiment is done.\n",
    "\n",
    "To put it more formally, if you draw random samples of size $n$, the distribution of the random variable  $\\overline{X}$, which consists of sample means, is called the sampling distribution of the mean. The sampling distribution of the mean approaches a normal distribution as $n$, the sample size, increases.\n",
    "\n",
    "The random variable  $\\overline{X}$  has a different $z$-score associated with it from that of the random variable $X$. The mean  $\\bar{x}$  is the value of  $\\overline{X}$ in one sample.\n",
    "\n",
    "$$ z = \\frac{\\bar{x} - \\mu_{\\overline{X}}}{\\sigma_{\\overline{X}}} $$\n",
    "\n",
    "$\\mu_X$ is the average of both $X$ and $\\overline{X}$.\n",
    "\n",
    "$\\sigma_{\\overline{X}} = \\frac{\\sigma_X}{\\sqrt{n}}$ = standard deviation of $\\overline{X}$ and is called the **standard error of the mean**.\n",
    "\n",
    "To illustrate this principle, consider a fair six-sided die. Since each outcome is equally likely, the expected value of rolling the die is\n",
    "\n",
    "$$ \\mu_X = \\frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5. $$\n",
    "\n",
    "We can also calculate that the population standard deviation is $\\sigma_X = 1.7078$.\n",
    "\n",
    "What does this mean? If we roll a die once, we certainly don't expect to get 3.5. But if we roll the die several times, we expect the average of those rolls to be reasonably close to 3.5. The more times we roll the die, the closer we expect the average of those rolls to be to 3.5. The Central Limit Theorem is the formal mathematical statement of this concept. \n",
    "\n",
    "The Central Limit Theorem tells us exactly how likely or unlikely getting an average from a sample is. Imagine we roll a die 50 times; that is, we \"sample\" 50 rolls. The Central Limit Theorem tells us that the means of *all* possible samples of 50 rolls form the normal distribution $\\overline{X} \\sim N(3.5, 1.7078/\\sqrt{50})$. We can use this to determine how likely or unlikely it is to randomly select a sample with a certain mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.1\n",
    "The expected value of a fair six-sided die roll is $\\mu_X = 3.5$. The standard deviation is $\\sigma_X = 1.7078$.\n",
    "\n",
    "1. If we roll the die 50 times, what is the likelihood that the sample mean is smaller than $3.0$?\n",
    "2. If we roll the die 100 times, what is the likelihood that the sample mean is smaller than $3.0$?\n",
    "3. Is it more likely that our sample mean is smaller than $3.0$ if we roll the die 50 times or 100 times? Why?\n",
    "\n",
    "#### Solution ####\n",
    "\n",
    "##### Part 1\n",
    "\n",
    "By the Central Limit Theorem, we know that means of samples of size 50 are normally distributed with mean \n",
    "\n",
    "$$\\mu_{\\overline{X}} = \\mu_X = 3.5$$ \n",
    "\n",
    "and with standard deviation\n",
    "\n",
    "$$\\sigma_{\\overline{X}} = \\frac{\\sigma_X}{\\sqrt{n}} = \\frac{1.7078}{\\sqrt{50}} = 0.2415$$\n",
    "\n",
    "We want to find $P(\\bar{x} < 3.0)$. Since $\\overline{X} \\sim N(3.5, 0.2415)$, we first find the $z$-score for $\\bar{x} = 3.0$.\n",
    "\n",
    "$$z = \\frac{\\bar{x} - \\mu_{\\overline{X}}}{\\sigma_{\\overline{X}}} = \\frac{3.0 - 3.5}{0.2415} = -2.0704. $$\n",
    "\n",
    "So $P(\\bar{x} < 3.0) = P(z < -2.0704)$. We use R to find the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0192074509255941"
      ],
      "text/latex": [
       "0.0192074509255941"
      ],
      "text/markdown": [
       "0.0192074509255941"
      ],
      "text/plain": [
       "[1] 0.01920745"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pnorm(q = -2.0704, lower.tail = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $P(\\bar{x} < 3.0) = P(z < -2.0704) = 0.0192$. That is, there is only a 1.92% chance that our 50 die rolls have an average of less than 3.0.\n",
    "\n",
    "##### Part 2\n",
    "By the Central Limit Theorem, we know that the means of samples of size 100 are normally distributed with mean\n",
    "\n",
    "$$ \\mu_{\\overline{X}} = \\mu_X = 3.5 $$\n",
    "\n",
    "and with standard deviation\n",
    "\n",
    "$$ \\sigma_{\\overline{X}} = \\frac{\\sigma_{X}}{\\sqrt{n}} = \\frac{1.7078}{\\sqrt{100}} = 0.1708. $$\n",
    "\n",
    "We want to find $P(\\bar{x} < 3.0)$. Since $\\overline{X} \\sim N(3.5, 0.1708)$, we first need to find the $z$-score associated with $\\bar{x} = 3.0$.\n",
    "\n",
    "$$ z = \\frac{\\bar{x} - \\mu_{\\overline{X}}}{\\sigma_{\\overline{X}}} = \\frac{3.0 - 3.5}{0.1708} = -2.9274. $$\n",
    "\n",
    "So $P(\\bar{x} < 3.0) = P(z < -2.9274)$. We use R to find the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.00170904480232814"
      ],
      "text/latex": [
       "0.00170904480232814"
      ],
      "text/markdown": [
       "0.00170904480232814"
      ],
      "text/plain": [
       "[1] 0.001709045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pnorm(q = -2.9274, lower.tail = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $P(\\bar{x} < 3.0) = P(z < -2.9274) = 0.0017$. That is, there is only a 0.17% chance that our 100 die rolls have an average of less than 3.0.\n",
    "\n",
    "##### Part 3\n",
    "The probability of getting a sample mean of less than 3.0 after 50 die rolls is 1.92%. But the probability of getting a sample mean of less than 3.0 after 100 die rolls is only 0.17%, more than 10 times smaller. We are much more likely to have a sample mean of less than 3.0 after only 50 die rolls than we are after 100 die rolls.\n",
    "\n",
    "This is because the larger our sample size, the more likely our sample mean will be close to the expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.2\n",
    "The length of time taken on the SAT for a group of students is normally distributed with a mean of 2.5 hours and a standard deviation of 0.85 hours. A sample size of $n = 30$ is drawn randomly from the population. Find the probability that the sample mean is between 2.3 hours and 2.7 hours.\n",
    "\n",
    "#### Solution\n",
    "By the Central Limit Theorem, sample means of samples of size $n = 30$ are normally distributed with\n",
    "\n",
    "$$ \\mu_{\\overline{X}} = \\mu_X = 2.5 $$\n",
    "\n",
    "and a standard deviation of\n",
    "\n",
    "$$ \\sigma_{\\overline{X}} = \\frac{\\sigma_X}{\\sqrt{n}} = \\frac{0.85}{\\sqrt{30}} = 0.1552; $$\n",
    "\n",
    "that is, $\\overline{X} \\sim N(2.5, 0.1552)$.\n",
    "\n",
    "We want to find $P(2.3 < \\bar{x} < 2.7)$. To do so, we first must find the $z$-scores associated with $\\bar{x} = 2.3$ and $\\bar{x} = 2.7$. We calculate\n",
    "\n",
    "$$ z = \\frac{\\bar{x} - \\mu_{\\overline{X}}}{\\sigma_{\\overline{X}}} = \\frac{2.3 - 2.5}{0.1552} = -1.2887, $$\n",
    "\n",
    "$$ z = \\frac{\\bar{x} - \\mu_{\\overline{X}}}{\\sigma_{\\overline{X}}} = \\frac{2.7 - 2.5}{0.1552} = 1.2887. $$\n",
    "\n",
    "Then $P(2.3 < \\bar{x} < 2.7) = P(-1.2887 < z < 1.2887)$. We will use R to find the probability. We will first find *all* the area to the left of $z = 1.2887$, then subtract off the excess area to the left of $z = -1.2887$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.802497597503648"
      ],
      "text/latex": [
       "0.802497597503648"
      ],
      "text/markdown": [
       "0.802497597503648"
      ],
      "text/plain": [
       "[1] 0.8024976"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pnorm(q = 1.2887, lower.tail = TRUE) - pnorm(q = -1.2887, lower.tail = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $P(2.3 < \\bar{x} < 2.7) = P(-1.2887 < z < 1.2887) = 0.8025$. There is an 80.25% chance that the sample of 30 individuals has a mean test time of between 2.3 and 2.7 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**VID=pQmC_Ft1huQ**#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.4 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**VID=_SrobSlBqjQ**#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution ##\n",
    "Significant portions of this textbook were written by Barbara Illowsky and Susan Dean in their textbook *Introductory Statistics*, published by OpenStax.\n",
    "\n",
    "Access for free at [https://openstax.org/books/introductory-statistics/pages/1-introduction](https://openstax.org/books/introductory-statistics/pages/1-introduction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
